{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, I am going to code from scratch the KNN algorithm. Many thanks to http://www.jiaaro.com/KNN-for-humans/ for his really simple and clear blogs The steps are: \n",
    "- Get your data\n",
    "- Standardize your features (I won't do it for this example, but the algorithm usually perform better with standardization)\n",
    "- create a function with the distance measures you want to use\n",
    "- Find the closest neightbour for every observation that you want to predict (you will see it's easier than it seems)\n",
    "- Make a vote \n",
    "- Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test data from a fruit list\n",
    "# example : the fruit we want to predict\n",
    "unknown_fruit = [373, 1]\n",
    "\n",
    "#  train dataset in list\n",
    "dataset = [\n",
    "  # weight, color, type\n",
    "  [303, 3, \"banana\"],\n",
    "  [370, 1, \"apple\"],\n",
    "  [298, 3, \"banana\"],\n",
    "  [277, 3, \"banana\"],\n",
    "  [377, 4, \"apple\"],\n",
    "  [299, 3, \"banana\"],\n",
    "  [382, 1, \"apple\"],\n",
    "  [374, 4, \"apple\"],\n",
    "  [303, 4, \"banana\"],\n",
    "  [309, 3, \"banana\"],\n",
    "  [359, 1, \"apple\"],\n",
    "  [366, 1, \"apple\"],\n",
    "  [311, 3, \"banana\"],\n",
    "  [302, 3, \"banana\"],\n",
    "  [373, 4, \"apple\"],\n",
    "  [305, 3, \"banana\"],\n",
    "  [371, 3, \"apple\"],\n",
    "]\n",
    "# convert the list into np.array\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will standardize our data so that every features (input,X) have zero mean and 1 unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will use the eucledienne distance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eucledienne_distance(fruit1, fruit2):\n",
    "    \"\"\"\n",
    "    The args are iterables of the values in the table. \n",
    "    for example the args should look something like this:\n",
    "    \n",
    "    #         weight,  color\n",
    "    fruit1 = [303,     3]  # Banana from the data set\n",
    "    fruit2 = [373,     1]  # the unclassified fruit\n",
    "    \"\"\"\n",
    "    \n",
    "    # first let's get the distance of each parameter\n",
    "    a = fruit1[0] - fruit2[0]\n",
    "    b = fruit1[1] - fruit2[1]\n",
    "    \n",
    "    # the distance from point A (fruit1) to point B (fruit2)\n",
    "    distance = (a**2 + b**2) **0.5\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Find the closest neightbour for every observation that you want to predict \n",
    "(you will see it's easier than it seems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banana', 96.020831073262428),\n",
       " ('banana', 75.026661927610775),\n",
       " ('banana', 74.027022093286988),\n",
       " ('banana', 71.028163428319047),\n",
       " ('banana', 70.064256222413434),\n",
       " ('banana', 70.028565600046392),\n",
       " ('banana', 68.029405406779802),\n",
       " ('banana', 64.031242374328485),\n",
       " ('banana', 62.032249677083293),\n",
       " ('apple', 14.0),\n",
       " ('apple', 9.0),\n",
       " ('apple', 7.0),\n",
       " ('apple', 5.0),\n",
       " ('apple', 3.1622776601683795),\n",
       " ('apple', 3.0),\n",
       " ('apple', 3.0),\n",
       " ('apple', 2.8284271247461903)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter, attrgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "features = dataset[:,0:2]\n",
    "features = features.astype(np.float)\n",
    "predictor = dataset[:,2]\n",
    "distances = [None]*len(features) # fill empty vector\n",
    "\n",
    "# compute the distance for every train row with the prediction. \n",
    "for row in range(0,len(features)):\n",
    "    distances[row] = eucledienne_distance(features[row], unknown_fruit)\n",
    "\n",
    "# append distance result with predictor\n",
    "# we can clearly see that apple will be selected with an appropriate k\n",
    "# because it has the lowest distance.\n",
    "\n",
    "neightbor_distance = zip(predictor,distances)\n",
    "sorted_dataset = sorted(neightbor_distance, \n",
    "                        key=itemgetter(1),reverse=True)#sorted with column2\n",
    "sorted_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a vote considering k every observation to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the python std library\n",
    "from collections import Counter\n",
    "\n",
    "# take only the first K items. What are the top 3 \n",
    "# fruit that are similar with test features and train features.\n",
    "top_k = sorted_dataset[:k]\n",
    "class_counts = Counter(fruit for (weight, color, fruit) in top_k)\n",
    "\n",
    "# class_counts now looks like this:\n",
    "# {\"apple\": 3}\n",
    "# we can see that the features in the train set that are in closest \n",
    "# distance with the test data relate to the apple.\n",
    "\n",
    "# get the class (fruit(apple or banana))  with the most votes\n",
    "classification = max(class_counts, key=lambda cls: class_counts[cls])\n",
    "\n",
    "# There you have it! the prediction is:\n",
    "classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
